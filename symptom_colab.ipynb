{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"mohammad2928git/complete_medical_symptom_dataset\")\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = dataset['train'].to_pandas()\n",
        "\n",
        "# Extract relevant columns and drop missing values\n",
        "df = df[['symptoms', 'text']].dropna()\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_df, validation_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Check the sizes of each dataset\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Validation size: {len(validation_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(df):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    for _, row in df.iterrows():\n",
        "        symptoms_list = row['symptoms']\n",
        "        text = row['text']\n",
        "\n",
        "        # Convert the list of symptoms into a string\n",
        "        symptoms_str = ', '.join([symptom.strip() for symptom in symptoms_list if isinstance(symptom, str) and symptom.strip()])\n",
        "\n",
        "        # Create inputs and targets\n",
        "        inputs.append(f\"extract symptoms: {text}\")\n",
        "        targets.append(symptoms_str)\n",
        "\n",
        "    return inputs, targets\n",
        "\n",
        "# Preprocess the training, validation, and test data\n",
        "train_inputs, train_targets = preprocess_data(train_df)\n",
        "validation_inputs, validation_targets = preprocess_data(validation_df)\n",
        "test_inputs, test_targets = preprocess_data(test_df)\n",
        "\n",
        "# Tokenize inputs and targets\n",
        "train_encodings = tokenizer(train_inputs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "train_labels = tokenizer(train_targets, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
        "\n",
        "validation_encodings = tokenizer(validation_inputs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "validation_labels = tokenizer(validation_targets, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
        "\n",
        "test_encodings = tokenizer(test_inputs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "test_labels = tokenizer(test_targets, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Create PyTorch Dataset\n",
        "class SymptomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SymptomDataset(train_encodings, train_labels)\n",
        "validation_dataset = SymptomDataset(validation_encodings, validation_labels)\n",
        "test_dataset = SymptomDataset(test_encodings, test_labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate at each epoch\n",
        "    learning_rate=5e-5,              # Learning rate\n",
        "    per_device_train_batch_size=4,   # Batch size for training\n",
        "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
        "    num_train_epochs=3,              # Number of training epochs\n",
        "    weight_decay=0.01,               # Weight decay for optimization\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,                # Log every 10 steps\n",
        "    save_strategy=\"epoch\",           # Save model at the end of each epoch\n",
        "    load_best_model_at_end=True,     # Load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_loss\",  # Metric to select the best model\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"trained_model\")\n",
        "tokenizer.save_pretrained(\"trained_model\")"
      ],
      "metadata": {
        "id": "4AOT6GUzVlJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k6xZI-ZPD39",
        "outputId": "ed9f6418-ca2e-4be7-cdc1-f5f4fe42720f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Path to the extracted model directory\n",
        "model_path = \"/content/drive/MyDrive/t5/doctor GPT/trained_model/trained_model\"\n",
        "\n",
        "# Load the tokenizer and model from the extracted directory\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Function to generate a response based on the input prompt\n",
        "def generate_response(prompt):\n",
        "    # Tokenize the input prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "    # Generate output with the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids,\n",
        "            max_length=150,      # Maximum length of the generated text\n",
        "            num_beams=5,         # Number of beams for beam search (optional)\n",
        "            early_stopping=True  # Stop early when the sentence is complete\n",
        "        )\n",
        "\n",
        "    # Decode the generated output into text\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "query = \"\"\"Another symptom that's been troubling me is gastrointestinal discomfort. I've experienced frequent episodes of nausea and vomiting, often unrelated to food intake. My appetite has significantly decreased, and I've noticed a sudden weight loss of about 10 pounds in just two weeks. There have been bouts of diarrhea alternating with constipation, and I sometimes experience sharp, cramping abdominal pain that seems to move around my midsection.\n",
        "In addition to these, I've had muscle aches and joint pain that seem to migrate from one area to another. The pain is most pronounced in my lower back and knees and tends to worsen in the evening. My energy levels have plummeted, leaving me feeling fatigued and lethargic throughout the day, regardless of how much sleep I get at night. Speaking of sleep, I've been struggling with insomnia, waking up frequently during the night and feeling unrested in the morning.\n",
        "On top of everything else, I've noticed a strange rash developing on my arms and legs. The rash is red, itchy, and occasionally forms small blisters that ooze a clear fluid. This skin issue is new and seems to correlate with increased exposure to sunlight, leading me to suspect a photosensitivity reaction.\"\"\"\n",
        "response = generate_response(f\"extract symptoms: {query}\")\n",
        "print(\"Extracted Symptoms:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVWGAvVRP_re",
        "outputId": "3ec0f0c5-0df9-4353-875f-529356b47cbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Symptoms: symptoms that's troubling me gastrointestinal discomfort, i've experienced frequent episodes nausea vomiting, unrelated food intake, appetite significantly decreased, i've noticed sudden weight loss 10 pounds just weeks, bouts diarrhea alternating cons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3at9QlJ9ShDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}